{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1afec7-5083-457d-bcc9-5c2e31536339",
   "metadata": {},
   "source": [
    "# Treinamento de Redes Neurais Artificiais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18c74c-dd98-4ff9-8dd8-956657baa102",
   "metadata": {},
   "source": [
    "**Disciplina:** Redes Neurais Artificiais 2025.1\n",
    "\n",
    "**Professora orientadora:** \n",
    "Elloa B. Guedes (ebgcosta@uea.edu.br)\n",
    "\n",
    "**Integrantes da equipe:**\n",
    "* Adriana Raffaella Dos Santos Fonseca (ardsf.eng23@uea.edu.br)\n",
    "* Ana Flavia De Castro Segadilha Da Silva (afdcsds.eng23@uea.edu.br)\n",
    "* Davi Aguiar Moreira (dam.eng23@uea.edu.br)\n",
    "* Guilherme Goncalves Moraes (ggm.eng23@uea.edu.br)\n",
    "* Ian Garrido Reis (igr.eng23@uea.edu.br)\n",
    "* Luiz Fernando Borges Brito (lfbb.eng23@uea.edu.br)\n",
    "* Pedro Vitor Barros Maranhão (pvbm.eng23@uea.edu.br)\n",
    "* Rita De Cassia Brasil Alves (rdcba.eng23@uea.edu.br)\n",
    "* Yago De Oliveira Feitoza (ydof.eng21@uea.edu.br)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a514b",
   "metadata": {},
   "source": [
    "## **Importação das bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "id": "48e56351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:27.286202Z",
     "start_time": "2025-06-09T21:24:27.268085Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer,accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "71cec956",
   "metadata": {},
   "source": [
    "### **Importação e Holdout do dataset**"
   ]
  },
  {
   "cell_type": "code",
   "id": "288c1f93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:27.898902Z",
     "start_time": "2025-06-09T21:24:27.883766Z"
    }
   },
   "source": [
    "file_path = 'modified_star_classification.csv'"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "268dc687-927a-45be-9720-81ec23deada4",
   "metadata": {},
   "source": [
    "Dada a expressiva quantidade de exemplos presentes no dataset, optou-se por dividir os dados por holdout 60/40. Além disso, a fim de possibilitar uma análise comparativa de abordagens posteriormente, utiliza-se um seed (42 por convenção)."
   ]
  },
  {
   "cell_type": "code",
   "id": "181bcb72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:28.316530Z",
     "start_time": "2025-06-09T21:24:27.964655Z"
    }
   },
   "source": [
    "df = pd.read_csv(file_path)\n",
    "\n",
    "y = df['class']\n",
    "X = df.drop('class', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Padroniza as características removendo a média e escalando para variância unitária.\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.fit_transform(X_test)\n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "3593be1a-8ec0-47b3-b338-fe6fd9425470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:28.335403Z",
     "start_time": "2025-06-09T21:24:28.317452Z"
    }
   },
   "source": [
    "type(X_train)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "aac7c6f6-264c-4a01-84ff-f0da4bc7a1df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:29.832503Z",
     "start_time": "2025-06-09T21:24:28.335917Z"
    }
   },
   "source": [
    "# Os datasets normalizados estão armazenados dentro da pasta holdout\n",
    "X_train.to_csv('holdout/x_train.csv', encoding='utf-8')\n",
    "X_test.to_csv('holdout/x_test.csv', encoding='utf-8')\n",
    "y_train.to_csv('holdout/y_train.csv', encoding='utf-8')\n",
    "y_test.to_csv('holdout/y_test.csv', encoding='utf-8')\n"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "ef7002d3",
   "metadata": {},
   "source": [
    "### **Abordagem 1: 60/40**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb9a3b-432b-472f-bdc4-fbfabcf396dc",
   "metadata": {},
   "source": [
    "Nesta abordagem, utiliza-se o holdout do modo como foi gerado anteriormente, isto é, sem o tratamento do desbalanceamento de dados. \n",
    "Checando o Holdout:"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5b15215-3f90-4c03-8c6f-b6755d8901af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:29.857583Z",
     "start_time": "2025-06-09T21:24:29.837907Z"
    }
   },
   "source": [
    "class_label_map = ['galaxy', 'star', 'quasar']\n",
    "training_labels_of_each_class = y_train.value_counts().tolist()\n",
    "sum_examples = sum(training_labels_of_each_class)\n",
    "percentage_by_class = {class_label: (class_examples/sum_examples)*100 for class_label, class_examples \n",
    "                       in zip(class_label_map, training_labels_of_each_class)}\n",
    "\n",
    "# Print percentages\n",
    "for i, (class_name, percentage) in enumerate(percentage_by_class.items(), start=0):\n",
    "    print(f'Class {i} ({class_name}): {percentage:.2f}%')\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 (galaxy): 59.53%\n",
      "Class 1 (star): 21.64%\n",
      "Class 2 (quasar): 18.83%\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "e804d7a8-9852-492d-b213-1470d00c8d0f",
   "metadata": {},
   "source": [
    "Nesse contexto, o conjunto de treinamento tem a seguinte composição: 59.53% dos são galáxias, 21.64% são estrelas e 18.83% são quasares. Desse modo, utilizam-se métricas ponderadas para permitir uma análise de resultados de acordo com a desigualdade no número de exemplos por classes."
   ]
  },
  {
   "cell_type": "code",
   "id": "3c94aea5-28e2-43be-980e-a532f165b30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:29.872277Z",
     "start_time": "2025-06-09T21:24:29.861558Z"
    }
   },
   "source": [
    "# Uso da pirâmide geométrica\n",
    "\n",
    "alpha = 3\n",
    "\n",
    "# Definindo Ni = Número de neurônios na camada de entrada (Número de features em x_train)\n",
    "Ni = 6 \n",
    "\n",
    "# Definindo No = Número de neurônios na camada de saída (Número de classes que são previstas em y_train)\n",
    "No = 3\n",
    "\n",
    "Nh = round((alpha*((Ni*No)**0.5)), 0)\n",
    "\n",
    "print(Nh)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "186af4b6-bd1e-4737-aa0d-7b15ff9567e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:29.890448Z",
     "start_time": "2025-06-09T21:24:29.875669Z"
    }
   },
   "source": [
    "# Construção de Arquiteturas\n",
    "\n",
    "# Arquiteturas nas quais 13 neurônios foram distribuídos em 2 camadas ocultas\n",
    "\n",
    "architectures = [\n",
    "    ((10, 3), 'adam', 'relu', 200, 1),      # 1\n",
    "    ((3, 10), 'sgd', 'tanh', 200, 1),       # 2\n",
    "    ((5, 8), 'adam', 'relu', 200, 1),       # 3\n",
    "    ((8, 5), 'sgd', 'tanh', 200, 1),        # 4\n",
    "    ((7, 6), 'sgd', 'tanh', 200, 1),        # 5\n",
    "    ((6, 7), 'adam', 'relu', 200, 1),       # 6\n",
    "    ((4, 9), 'sgd', 'relu', 200, 1),        # 7\n",
    "    ((9, 4), 'adam', 'logistic', 200, 1),   # 8\n",
    "    ((2, 11), 'adam', 'relu', 200, 1),      # 9\n",
    "    ((11, 2), 'adam', 'logistic', 200, 1),  # 10\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "69617dea10ec0041",
   "metadata": {},
   "source": [
    "Além das arquiteturas propostas através da regra da pirâmide, são testadas outras cinco arquiteturas com número de neurônios arbitrários dentro da camada oculta e como elas se desempenhavam."
   ]
  },
  {
   "cell_type": "code",
   "id": "4ded6033104d49bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:29.905837Z",
     "start_time": "2025-06-09T21:24:29.891411Z"
    }
   },
   "source": [
    "arbitrary_architectures = [\n",
    "    ((32, 64), 'adam', 'relu', 200, 1),       # 1\n",
    "    ((48, 64), 'adam', 'logistic', 200, 1),   # 2\n",
    "    ((12, 12), 'adam', 'tanh', 200, 1),       # 3\n",
    "    ((36, 24), 'adam', 'relu', 200, 1),       # 4\n",
    "    ((28, 28), 'sgd', 'tanh', 200, 1),        # 5\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "7fdefeb87c1e785d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T21:24:29.934404Z",
     "start_time": "2025-06-09T21:24:29.914841Z"
    }
   },
   "source": [
    "# Função de treino das arquiteturas\n",
    "\n",
    "# Treinamento das arquiteturas propostas com auxílio da regra de pirâmide de acordo com (método 1)\n",
    "\n",
    "def train_model(X_train, X_test, y_train, y_test, layers, solver, activation, iterations, n_times, lr=1e-3):\n",
    "    results = []\n",
    "    print(f'Arquitetura com solver = {solver},' ,\n",
    "          f' activation = {activation}',\n",
    "          f'camadas ocultas={layers} ',\n",
    "          f'Taxa de aprendizado={lr}',\n",
    "          f'e n° de iterações={iterations} por {n_times}')\n",
    "\n",
    "    for i in range(1, n_times + 1):\n",
    "        print(f\"Execução {i}/{n_times}\")\n",
    "\n",
    "        # Treinamento\n",
    "        model = MLPClassifier(hidden_layer_sizes = layers,\n",
    "                              solver = solver,\n",
    "                              activation = activation,\n",
    "                              max_iter = iterations,\n",
    "                              learning_rate_init = lr,\n",
    "                              n_iter_no_change = 10,\n",
    "                              random_state = i,\n",
    "                              early_stopping = True,\n",
    "                              verbose=False\n",
    "                              )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc_score = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        results.append([acc_score, precision, recall, f1])\n",
    "\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "7caa7ddb-2c17-48c4-8734-0842d98e415d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-09T21:24:29.939985Z"
    }
   },
   "source": [
    "architectures_results_method1 = []\n",
    "\n",
    "for i, (layers, solver, activation, iterations, n_times) in enumerate(architectures, start=1):\n",
    "    print(f'\\n Treinando Arquitetura {i}/10')\n",
    "    res = train_model(X_train_std, X_test_std, y_train, y_test,\n",
    "                      layers, solver, activation, iterations, n_times)\n",
    "    architectures_results_method1.append(res)\n",
    "         \n",
    "medias_architectures_results_method1  = []\n",
    "desvios_architectures_results_method1 = []\n",
    "\n",
    "for result in architectures_results_method1:\n",
    "    result = np.array(result)\n",
    "    medias_architectures_results_method1.append(np.mean(result, axis=0).tolist())\n",
    "    desvios_architectures_results_method1 .append(np.std(result, axis=0).tolist())\n",
    "    \n",
    "# Construção da Tabela usando Prettytable\n",
    "table = PrettyTable()\n",
    "table.title= 'Treinamento de arquiteturas com método da pirâmide | Hold-Out 60/40'\n",
    "table.field_names = ['Arquitetura', 'Acurácia','Precisão','Revocação','F1-Score']\n",
    "\n",
    "# Adicionando os campos da tabela\n",
    "for i in range(len(architectures)):\n",
    "    table.add_row([f'{i+1}',\n",
    "                   f'{medias_architectures_results_method1[i][0]:.4f} ± {desvios_architectures_results_method1[i][0]:.4f}',\n",
    "                   f'{medias_architectures_results_method1[i][1]:.4f} ± {desvios_architectures_results_method1[i][1]:.4f}',\n",
    "                   f'{medias_architectures_results_method1[i][2]:.4f} ± {desvios_architectures_results_method1[i][2]:.4f}',\n",
    "                   f'{medias_architectures_results_method1[i][3]:.4f} ± {desvios_architectures_results_method1[i][3]:.4f}'\n",
    "                   ])\n",
    "print(table)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Treinando Arquitetura 1/10\n",
      "Arquitetura com solver = adam,  activation = relu camadas ocultas=(10, 3)  Taxa de aprendizado=0.001 e n° de iterações=200 por 1\n",
      "Execução 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritab\\PycharmProjects\\rna\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:787: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Treinando Arquitetura 2/10\n",
      "Arquitetura com solver = sgd,  activation = tanh camadas ocultas=(3, 10)  Taxa de aprendizado=0.001 e n° de iterações=200 por 1\n",
      "Execução 1/1\n",
      "\n",
      " Treinando Arquitetura 3/10\n",
      "Arquitetura com solver = adam,  activation = relu camadas ocultas=(5, 8)  Taxa de aprendizado=0.001 e n° de iterações=200 por 1\n",
      "Execução 1/1\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0ec66e00-d24a-41c2-8fcc-e36a18ab0f0a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "2d01ee6c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Treinamento das arquiteturas propostas arbitrariamente de acordo com (método 1)\n",
    "\n",
    "arbitrary_architectures_results_method1 = []\n",
    "\n",
    "for i, (layers, solver, activation, iterations, n_times) in enumerate(arbitrary_architectures, start=1):\n",
    "    print(f'\\n Treinando Arquitetura {i}/5')\n",
    "    res = train_model(X_train_std, X_test_std, y_train, y_test,\n",
    "                      layers, solver, activation, iterations, n_times)\n",
    "    arbitrary_architectures_results_method1.append(res)\n",
    "\n",
    "medias_arbitrary_architectures_results_method1  = []\n",
    "desvios_arbitrary_architectures_results_method1 = []\n",
    "\n",
    "for result in arbitrary_architectures_results_method1:\n",
    "    result = np.array(result)\n",
    "    medias_arbitrary_architectures_results_method1 .append(np.mean(result, axis=0).tolist())\n",
    "    desvios_arbitrary_architectures_results_method1.append(np.std(result, axis=0).tolist())\n",
    "\n",
    "# Construção da Tabela usando Prettytable\n",
    "table = PrettyTable()\n",
    "table.title= 'Treinamento de arquiteturas arbitrárias | Hold-Out 60/40'\n",
    "table.field_names = ['Arquitetura', 'Acurácia','Precisão','Revocação','F1-Score']\n",
    "\n",
    "# Adicionando os campos da tabela\n",
    "for i in range(len(arbitrary_architectures)):\n",
    "    table.add_row([f'{i+1}',\n",
    "                   f'{medias_arbitrary_architectures_results_method1[i][0]:.4f} ± {desvios_arbitrary_architectures_results_method1[i][0]:.4f}',\n",
    "                   f'{medias_arbitrary_architectures_results_method1[i][1]:.4f} ± {desvios_arbitrary_architectures_results_method1[i][1]:.4f}',\n",
    "                   f'{medias_arbitrary_architectures_results_method1[i][2]:.4f} ± {desvios_arbitrary_architectures_results_method1[i][2]:.4f}',\n",
    "                   f'{medias_arbitrary_architectures_results_method1[i][3]:.4f} ± {desvios_arbitrary_architectures_results_method1[i][3]:.4f}'\n",
    "                   ])\n",
    "print(table)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "97c4e1f779b206ed",
   "metadata": {},
   "source": [
    "### **Obtendo a melhor arquitetura utilizando o método 1**"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab7843e870fc0998",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Agrupa todas as arquiteturas \n",
    "all_architectures = architectures + arbitrary_architectures\n",
    "\n",
    "# Agrupa toda a lista de médias \n",
    "all_means = medias_architectures_results_method1 + medias_arbitrary_architectures_results_method1\n",
    "\n",
    "# Extrai apenas a média de f1-scores\n",
    "f1_scores = [m[3] for m in all_means]\n",
    "\n",
    "top1_idx = int(np.argmax(f1_scores))\n",
    "top1_method1_f1 = f1_scores[top1_idx]\n",
    "top1_method1_params = all_architectures[top1_idx]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3fb504bb",
   "metadata": {},
   "source": [
    "### **Abordagem 2: Downsampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b9a05-007a-4678-b6a1-6f3932a8da68",
   "metadata": {},
   "source": [
    "Esta abordagem se dá por downsampling, i.e., iguala-se a quantidade de exemplos para cada dado a fim de permitir que o treinamento não se vicie em prever a classe majoritária."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d6989",
   "metadata": {},
   "source": [
    "**Balanceando as classes**"
   ]
  },
  {
   "cell_type": "code",
   "id": "7f8d1e83",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "X_train_std_df = pd.DataFrame(X_train_std, columns=X.columns, index=X_train.index)\n",
    "X_test_std_df = pd.DataFrame(X_test_std, columns=X.columns, index=X_test.index)\n",
    "train_df = pd.concat([X_train_std_df, y_train], axis=1)\n",
    "\n",
    "class_counts = train_df['class'].value_counts()\n",
    "\n",
    "min_count = class_counts.min()\n",
    "\n",
    "balanced_dfs = []\n",
    "\n",
    "for class_name in class_counts.index:\n",
    "    class_df = train_df[train_df['class'] == class_name]\n",
    "    balanced_dfs.append(class_df.sample(min_count, random_state=42))\n",
    "\n",
    "balanced_train_df = pd.concat(balanced_dfs)\n",
    "\n",
    "X_train_balanced = balanced_train_df.drop('class', axis=1)\n",
    "y_train_balanced = balanced_train_df['class']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9e0f73f7d7709b0",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "y_train_balanced.value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1c55d81681c99da0",
   "metadata": {},
   "source": [
    "Como é possível observar, são 11299 exemplos para cada 1 das três classes de predição."
   ]
  },
  {
   "cell_type": "code",
   "id": "8835097d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.countplot(data=df, x='class', color='skyblue')\n",
    "plt.title(f'Distribuição das classes')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Frequência')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.countplot(data=balanced_train_df, x='class', color='skyblue')\n",
    "plt.title(f'Distribuição das classes após downsampling')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Frequência')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f56129e4c1611304",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Treinamento das arquiteturas propostas com auxílio da regra de pirâmide de acordo com (método 2)\n",
    "\n",
    "architectures_results_method2 = []\n",
    "\n",
    "for i, (layers, solver, activation, iterations, n_times) in enumerate(architectures, start=1):\n",
    "    print(f'\\n Treinando Arquitetura {i}/10')\n",
    "    res = train_model(X_train_balanced, X_test_std_df, y_train_balanced, y_test,\n",
    "                      layers, solver, activation, iterations, n_times)\n",
    "    architectures_results_method2.append(res)\n",
    "\n",
    "medias_architectures_results_method2 = []\n",
    "desvios_architectures_results_method2 = []\n",
    "\n",
    "for result in architectures_results_method2:\n",
    "    result = np.array(result)\n",
    "    medias_architectures_results_method2.append(np.mean(result, axis=0).tolist())\n",
    "    desvios_architectures_results_method2.append(np.std(result, axis=0).tolist())\n",
    "\n",
    "# Construção da Tabela usando Prettytable\n",
    "table = PrettyTable()\n",
    "table.title= 'Treinamento de arquiteturas com método da pirâmide | Downsampling'\n",
    "table.field_names = ['Arquitetura', 'Acurácia','Precisão','Revocação','F1-Score']\n",
    "\n",
    "# Adicionando os campos da tabela\n",
    "for i in range(len(arbitrary_architectures)):\n",
    "    table.add_row([f'{i+1}',\n",
    "                   f'{medias_architectures_results_method2[i][0]:.4f} ± {desvios_architectures_results_method2[i][0]:.4f}',\n",
    "                   f'{medias_architectures_results_method2[i][1]:.4f} ± {desvios_architectures_results_method2[i][1]:.4f}',\n",
    "                   f'{medias_architectures_results_method2[i][2]:.4f} ± {desvios_architectures_results_method2[i][2]:.4f}',\n",
    "                   f'{medias_architectures_results_method2[i][3]:.4f} ± {desvios_architectures_results_method2[i][3]:.4f}'\n",
    "                   ])\n",
    "print(table)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3b445a3-d7a1-471b-96a6-91239947df5c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Treinamento das arquiteturas propostas com auxílio da regra de pirâmide de acordo com (método 2)\n",
    "\n",
    "arbitrary_results_architectures_results_method2 = []\n",
    "\n",
    "for i, (layers, solver, activation, iterations, n_times) in enumerate(arbitrary_architectures, start=1):\n",
    "    print(f'\\n Treinando Arquitetura {i}/5')\n",
    "    res = train_model(X_train_balanced, X_test_std_df, y_train_balanced, y_test,\n",
    "                      layers, solver, activation, iterations, n_times)\n",
    "    arbitrary_results_architectures_results_method2.append(res)\n",
    "\n",
    "medias_arbitrary_results_architectures_results_method2 = []\n",
    "desvios_arbitrary_results_architectures_results_method2 = []\n",
    "\n",
    "for result in arbitrary_results_architectures_results_method2:\n",
    "    result = np.array(result)\n",
    "    medias_arbitrary_results_architectures_results_method2 .append(np.mean(result, axis=0).tolist())\n",
    "    desvios_arbitrary_results_architectures_results_method2.append(np.std(result, axis=0).tolist())\n",
    "\n",
    "# Construção da Tabela usando Prettytablez\n",
    "table = PrettyTable()\n",
    "table.title= 'Treinamento de arquiteturas arbitrárias | Downsampling'\n",
    "table.field_names = ['Arquitetura', 'Acurácia','Precisão','Revocação','F1-Score']\n",
    "\n",
    "# Adicionando os campos da tabela\n",
    "for i in range(len(arbitrary_architectures)):\n",
    "    table.add_row([f'{i+1}',\n",
    "                   f'{medias_arbitrary_results_architectures_results_method2[i][0]:.4f} ± {desvios_arbitrary_results_architectures_results_method2[i][0]:.4f}',\n",
    "                   f'{medias_arbitrary_results_architectures_results_method2[i][1]:.4f} ± {desvios_arbitrary_results_architectures_results_method2[i][1]:.4f}',\n",
    "                   f'{medias_arbitrary_results_architectures_results_method2[i][2]:.4f} ± {desvios_arbitrary_results_architectures_results_method2[i][2]:.4f}',\n",
    "                   f'{medias_arbitrary_results_architectures_results_method2[i][3]:.4f} ± {desvios_arbitrary_results_architectures_results_method2[i][3]:.4f}'\n",
    "                   ])\n",
    "print(table)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "355d635c",
   "metadata": {},
   "source": [
    "### **Obtendo a melhor arquitetura utilizando o método 2**"
   ]
  },
  {
   "cell_type": "code",
   "id": "b87c8222872f6eab",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Agrupa todas as arquiteturas \n",
    "all_architectures = architectures + arbitrary_architectures\n",
    "\n",
    "# Agrupa toda a lista de médias \n",
    "all_means = medias_architectures_results_method2 + medias_arbitrary_results_architectures_results_method2\n",
    "\n",
    "# Extrai apenas a média de f1-scores\n",
    "f1_scores = [m[3] for m in all_means]\n",
    "\n",
    "top1_idx = int(np.argmax(f1_scores))\n",
    "top1_method2_f1 = f1_scores[top1_idx]\n",
    "top1_method2_params = all_architectures[top1_idx]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c2890ad5-5c67-4799-9fa1-9efdb5662d0a",
   "metadata": {},
   "source": [
    "**Análise de métricas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78492195-4c86-45b9-bcb9-25e74811845d",
   "metadata": {},
   "source": [
    "Diante da análise dos valores de F1-Score de ambas as abordagens para o mesmo conjunto de testes, nota-se proximidade entre os valores. Tal proximidade se deu para uma única execução de um único modelo para cada abordagem, sendo possível que outras execuções favoreçam uma abordagem em dentrimento da outra.\n",
    "\n",
    "Nesse cenário, a segunda abordagem mostra-se viável, dado que permite a obtenção de um métrica próxima à primeira, com uma quantidade de dados muito menor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c08a27-5bea-4f3c-9152-033986344a31",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "id": "5422a3ce-a702-403b-b07a-f5ff6a961e22",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Função que realiza o grid\n",
    "def grid_search(mlp, parameters, scorers, X, y):\n",
    "    search = GridSearchCV(mlp, parameters, scoring=scorers, n_jobs=-1, verbose=2, refit='f1-score')\n",
    "    search.fit(X,y)\n",
    "    return search.cv_results_, search.best_params_, search.best_score_, search.best_estimator_\n",
    "\n",
    "# Parâmetros do Grid Search\n",
    "parameters = {\n",
    "    # 'solver': ['adam', 'sgd'], # Solver\n",
    "    'batch_size': [100, 200], # Tamanho de lote\n",
    "    # 'learning_rate_init': [0.0001, 0.001, 0.01], # Taxa de aprendizado\n",
    "    # 'n_iter_no_change': [10, 20], # Paciência\n",
    "    # 'max_iter': [100, 200] # Número de épocas\n",
    "}\n",
    "\n",
    "# Métricas utilizadas \n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1-score': make_scorer(f1_score, average='weighted'),\n",
    "    'revocação': make_scorer( recall_score, average='weighted'),\n",
    "    'precisão':make_scorer(precision_score, average='weighted')\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c42a1d522bd2e87b",
   "metadata": {},
   "source": [
    "### **Matriz de Confusão das 2 melhores arquiteturas utilizando o melhores hiperparâmetros encontrados para a mesmas**"
   ]
  },
  {
   "cell_type": "code",
   "id": "668d1a61806c6ad5",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Parâmetros da arquitetura top 1 do método 1\n",
    "layers, solver, activation, _ , _ = top1_method1_params\n",
    "\n",
    "# Declarando o modelo que vai ser utilizado dentro do grid\n",
    "model = MLPClassifier(hidden_layer_sizes=layers,\n",
    "                      solver=solver,\n",
    "                      activation=activation,\n",
    "                      alpha=0.001,\n",
    "                      learning_rate_init=0.001,\n",
    "                      n_iter_no_change=10,\n",
    "                      max_iter=200,\n",
    "                      random_state=42,\n",
    "                      early_stopping=True\n",
    "                      )\n",
    "\n",
    "print(f\"\\nExecutando Grid Search para arquitetura: {layers}, {solver}, {activation}\")\n",
    "\n",
    "_ , best_paremeters, _ , best_estimator = grid_search(model, parameters, scorers, X_train_std, y_train)\n",
    "\n",
    "# Treina modelo final com melhores parâmetros\n",
    "best_model_1 = best_estimator\n",
    "best_model_1.fit(X_train_std, y_train)\n",
    "y_pred = best_model_1.predict(X_test_std)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"\\nMelhores parâmetros: {best_paremeters}\")\n",
    "print(f\"Acurácia: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Plota matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_label_map)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f\"Matriz de Confusão - Arquitetura {layers}\\n{solver}, {activation}\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6643b896c7f7270",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Parâmetros da arquitetura top 1 do método 1\n",
    "layers, solver, activation, _ , _ = top1_method2_params\n",
    "\n",
    "# Declarando o modelo que vai ser utilizado dentro do grid\n",
    "model = MLPClassifier(hidden_layer_sizes=layers,\n",
    "                      solver=solver,\n",
    "                      activation=activation,\n",
    "                      alpha=0.001,\n",
    "                      learning_rate_init=0.001,\n",
    "                      n_iter_no_change=10,\n",
    "                      max_iter=200,\n",
    "                      random_state=42,\n",
    "                      early_stopping=True\n",
    "                      )\n",
    "\n",
    "print(f\"\\nExecutando Grid Search para arquitetura: {layers}, {solver}, {activation}\")\n",
    "\n",
    "_ , best_paremeters, _ , best_estimator = grid_search(model, parameters, scorers, X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Treina modelo final com melhores parâmetros\n",
    "best_model_2 = best_estimator\n",
    "best_model_2.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = best_model_2.predict(X_test_std)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"\\nMelhores parâmetros: {best_paremeters}\")\n",
    "print(f\"Acurácia: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Plota matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_label_map)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f\"Matriz de Confusão - Arquitetura {layers}\\n{solver}, {activation}\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f4c85b4d802b1d62",
   "metadata": {},
   "source": [
    "### **Como o melhor modelo se comporta sem o 'weighted'?** ###"
   ]
  },
  {
   "cell_type": "code",
   "id": "672db286d9f59433",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Treinando o melhor modelo mais uma vez.\n",
    "best_model_1.fit(X_train_std, y_train)\n",
    "y_pred = best_model_1.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Retirando o weighted e colocando macro\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"\\nMelhores parâmetros: {best_paremeters}\")\n",
    "print(f\"Acurácia: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Plota matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_label_map)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f\"Matriz de Confusão - Arquitetura {layers}\\n{solver}, {activation}\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "21d63423-73b0-4c5d-a853-2a3411c780cb",
   "metadata": {},
   "source": "**Modelo final**  "
  },
  {
   "cell_type": "code",
   "id": "8074d61d-3e71-4ee7-879b-1a5f5d8998db",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "joblib.dump(best_model_1, 'mlp_model.joblib')\n",
    "\n",
    "def recuperar_modelo():\n",
    "    return joblib.load('mlp_model.joblib')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Realizando uma predição final",
   "id": "b34653f257ae2f85"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "linha_teste = df.iloc[[32765]]\n",
    "teste = scaler.transform(linha_teste.drop('class', axis=1))\n",
    "teste "
   ],
   "id": "5b896e6d63b09e80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "rna = recuperar_modelo()",
   "id": "d54df7e8724cd752",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Qual a classificação correta do objeto?\n",
    "linha_teste['class']"
   ],
   "id": "1be2730f57c223cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# A rede artifical classificou como:\n",
    "rna.predict(teste)"
   ],
   "id": "b2da447909659641",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
